{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "yWCZvvOTJJQV",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Importation of functions/libraries to be used in the classification\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer #lexical database for English language that offer lemmatization\n",
    "from sklearn.preprocessing import LabelEncoder #converting the labels into numeric form \n",
    "from collections import defaultdict\n",
    "from nltk.corpus import wordnet as wn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer # Transforms text to feature vectors\n",
    "from sklearn import model_selection, naive_bayes\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#from sklearn.linear_model.logistic import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score \n",
    "import matplotlib.pyplot as plt #For visualization\n",
    "import xlrd\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 36.2 s\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "#my_path = r'C:\\Users\\216068813\\Documents'\n",
    "my_path = r'E:\\Japheth Mursi docs\\Python'\n",
    "%time df = pd.read_excel(os.path.join(my_path,'PD1_5.xlsx'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "id": "NoiQWZOiax2m",
    "outputId": "3f857dc9-822a-4869-992b-66925aac9983"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-e196758c-12d5-4c78-8473-14212e225588\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-e196758c-12d5-4c78-8473-14212e225588\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving PD1_5.xlsx to PD1_5.xlsx\n"
     ]
    }
   ],
   "source": [
    "#%pip install sklearn_pandas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from google.colab import files\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lrqbyfffqG4T"
   },
   "source": [
    "## 1: Load  dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ivVCnatKcS3O"
   },
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "df= pd.read_excel(io.BytesIO(uploaded['PD1_5.xlsx']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "74xU0rbKrtTl",
    "outputId": "b88ec4f7-6745-4556-b30f-31fe8e9128c0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49193, 36)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get the shape of the dataset\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "DYABSTVIrdUX"
   },
   "outputs": [],
   "source": [
    "#chunk.clean_text=chunk.clean_text.astype(str)\n",
    "df.pt1=df.pt1.astype(str)\n",
    "df.pt2=df.pt2.astype(str)\n",
    "df.pt3=df.pt3.astype(str)\n",
    "df.pt4=df.pt4.astype(str)\n",
    "df.pt5=df.pt5.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sBTLj517rdUs"
   },
   "source": [
    "## 2: Import ML libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "MyzWo9TguJrj"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rEE_BJww_Cx9"
   },
   "outputs": [],
   "source": [
    "df= df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tpq6PpbFrdU9"
   },
   "source": [
    "## 3: Declare predictors and target variable\n",
    "The prediction Model is developed using a three feature vectors/ attributes:\n",
    "* <T:Clean_text>: Preprocessed tweet\n",
    "* <W:Weightage>: Presence or absence of narcissistic related word/Clean text based on the narcissistic dictionary\n",
    "* <S: Statuses Count>: Number of tweets (statuses posted) made by the user. We classify tweets made by users into three categories for the purspose to classifier training as follows; \n",
    "    * Users with tweets Less than 10,000;\n",
    "\t* Users with tweets above 10000 but less than 50,000;\n",
    "\t* Users with tweets More than 50,000 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 448
    },
    "id": "qpZga_2Nax25",
    "outputId": "038db98c-0b00-4327-c2ff-4792439308e9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>pt1</th>\n",
       "      <th>pt2</th>\n",
       "      <th>pt3</th>\n",
       "      <th>tokens</th>\n",
       "      <th>stems</th>\n",
       "      <th>pt4</th>\n",
       "      <th>lemmas</th>\n",
       "      <th>pt5</th>\n",
       "      <th>SS1</th>\n",
       "      <th>...</th>\n",
       "      <th>Gn</th>\n",
       "      <th>Vn5</th>\n",
       "      <th>Gn5</th>\n",
       "      <th>Vn1</th>\n",
       "      <th>Gn1</th>\n",
       "      <th>Vn2</th>\n",
       "      <th>Gn2</th>\n",
       "      <th>Vn3</th>\n",
       "      <th>Gn3</th>\n",
       "      <th>SPL5.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is the worst year possible to be obsessed...</td>\n",
       "      <td>this is the worst year possible to be obsessed...</td>\n",
       "      <td>this is the worst year possible to be obsessed...</td>\n",
       "      <td>worst year possible obsessed someone want ever...</td>\n",
       "      <td>['worst', 'year', 'possible', 'obsessed', 'som...</td>\n",
       "      <td>['worst', 'year', 'possibl', 'obsess', 'someon...</td>\n",
       "      <td>worst year possibl obsess someon want everi si...</td>\n",
       "      <td>worst year possible obsessed someone want ever...</td>\n",
       "      <td>bad year possible obsess someone want every si...</td>\n",
       "      <td>-0.467857</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tony Blair extract worse than thought of paren...</td>\n",
       "      <td>tony blair extract worse than thought of paren...</td>\n",
       "      <td>tony blair extract worse than thought of paren...</td>\n",
       "      <td>tony blair extract worse thought parents sex i...</td>\n",
       "      <td>['tony', 'blair', 'extract', 'worse', 'thought...</td>\n",
       "      <td>['toni', 'blair', 'extract', 'wors', 'thought'...</td>\n",
       "      <td>toni blair extract wors thought parent sex ira...</td>\n",
       "      <td>tony blair extract worse thought parents sex i...</td>\n",
       "      <td>tony blair extract bad thought parent sex iraq...</td>\n",
       "      <td>-0.466667</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  This is the worst year possible to be obsessed...   \n",
       "1  Tony Blair extract worse than thought of paren...   \n",
       "\n",
       "                                                 pt1  \\\n",
       "0  this is the worst year possible to be obsessed...   \n",
       "1  tony blair extract worse than thought of paren...   \n",
       "\n",
       "                                                 pt2  \\\n",
       "0  this is the worst year possible to be obsessed...   \n",
       "1  tony blair extract worse than thought of paren...   \n",
       "\n",
       "                                                 pt3  \\\n",
       "0  worst year possible obsessed someone want ever...   \n",
       "1  tony blair extract worse thought parents sex i...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  ['worst', 'year', 'possible', 'obsessed', 'som...   \n",
       "1  ['tony', 'blair', 'extract', 'worse', 'thought...   \n",
       "\n",
       "                                               stems  \\\n",
       "0  ['worst', 'year', 'possibl', 'obsess', 'someon...   \n",
       "1  ['toni', 'blair', 'extract', 'wors', 'thought'...   \n",
       "\n",
       "                                                 pt4  \\\n",
       "0  worst year possibl obsess someon want everi si...   \n",
       "1  toni blair extract wors thought parent sex ira...   \n",
       "\n",
       "                                              lemmas  \\\n",
       "0  worst year possible obsessed someone want ever...   \n",
       "1  tony blair extract worse thought parents sex i...   \n",
       "\n",
       "                                                 pt5       SS1  ...  Gn  Vn5  \\\n",
       "0  bad year possible obsess someone want every si... -0.467857  ...   0    0   \n",
       "1  tony blair extract bad thought parent sex iraq... -0.466667  ...   0    0   \n",
       "\n",
       "   Gn5  Vn1 Gn1  Vn2  Gn2 Vn3  Gn3 SPL5.1  \n",
       "0    0    0   0    0    0   0    0    NaN  \n",
       "1    0    0   0    0    0   0    0    NaN  \n",
       "\n",
       "[2 rows x 36 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dk=df\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g3d3mZjdrXG0"
   },
   "outputs": [],
   "source": [
    "df.pt4=df.pt4.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "fG3gqKZ5_CyD"
   },
   "outputs": [],
   "source": [
    "#Add the features of the dataframe that you want to transform and/or combine\n",
    "mapper = DataFrameMapper([\n",
    "     ('pt1', TfidfVectorizer(min_df=.0025, max_df=0.8, stop_words='english',ngram_range=(1,2))),#max_df=0.8, min_df=2),\n",
    "     ])\n",
    "    #('No_of_category',None),\n",
    "     #('Vn5', None)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qybsEBchrvy9"
   },
   "source": [
    "## 4a:Split the dataset to training and test dataset and map features to target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cb2i15Itt7hu",
    "outputId": "0437810d-f4bd-4b28-aaf5-9f1846886b0d"
   },
   "outputs": [],
   "source": [
    "#Map predictor Variables to Target Variable\n",
    "features = mapper.fit_transform(df)\n",
    "categories = df['SPL1']\n",
    " \n",
    "# Split the data between train and test\n",
    "#X_Train, X_Test, Y_Train, Y_Test = train_test_split(features, categories ,test_size=0.2,train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "g42_YdJlax27"
   },
   "outputs": [],
   "source": [
    "# Split the data between train and test\n",
    "X_Train, X_Test, Y_Train, Y_Test = train_test_split(features, categories ,test_size=0.2,train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bYuJYB4dax28",
    "outputId": "c850ba34-f403-4b8a-e240-e2dac52ae42d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39354, 692)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Show the size of the split train and test dataset\n",
    "X_Train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7vCI-2wWrdWF"
   },
   "source": [
    "## 4b:Training using selected ML Classifiers\n",
    "Training refers to the process where we “teach” the classifier (e.g naïve bayes )\n",
    "by using “fit” to the training data  (X_Train , Y_Train) to be able to \n",
    "learn data attributes and evaluate its accuracy based on the (20%) test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rF-ZHiA2v_zA",
    "outputId": "6a74b8d1-2f2a-4220-f456-c5001f512384"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy Score ->  83.44343937392011\n"
     ]
    }
   ],
   "source": [
    "# fit the training dataset on the NB classifier\n",
    "Naive = naive_bayes.MultinomialNB()\n",
    "Naive=MultinomialNB().fit(X_Train,Y_Train)\n",
    "Naive.fit(X_Train,Y_Train) #Fit the model according to the given training data\n",
    "# predict the labels on test dataset\n",
    "NB_pred = Naive.predict(X_Test)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"Naive Bayes Accuracy Score -> \",accuracy_score(NB_pred, Y_Test)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jC7CdLcjax2-",
    "outputId": "fd27855e-b09a-4e17-cba4-112876bce09e",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7462   13   27]\n",
      " [ 489   96   14]\n",
      " [1074   12  652]]\n",
      "Accuracy0.8344343937392011\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "NB_pred_CM = confusion_matrix(Y_Test, NB_pred)\n",
    "print(NB_pred_CM)\n",
    "print('Accuracy' + str(accuracy_score(Y_Test, NB_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ly8wDDHtax2-",
    "outputId": "f8e295d5-a54b-4de0-b198-447cb52e7b08",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.99      0.90      7502\n",
      "           1       0.79      0.16      0.27       599\n",
      "           2       0.94      0.38      0.54      1738\n",
      "\n",
      "    accuracy                           0.83      9839\n",
      "   macro avg       0.85      0.51      0.57      9839\n",
      "weighted avg       0.84      0.83      0.80      9839\n",
      "\n",
      "\n",
      "0.8344343937392011\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_Test, NB_pred))\n",
    "print()\n",
    "print(accuracy_score(Y_Test, NB_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_tADLxc2ax3D"
   },
   "source": [
    "###  RF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kpuWvdniax3D"
   },
   "outputs": [],
   "source": [
    "#Random forest accuracy with three predictor variables\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "Rf2 = RandomForestClassifier(n_estimators=180,max_leaf_nodes=None, \n",
    "                                 n_jobs=-1)\n",
    "Rf2.fit(X_Train,Y_Train)\n",
    "Rf2_pred = Rf2.predict(X_Test)\n",
    "print('Random forest accuracy %s' % accuracy_score(Rf2_pred , Y_Test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SExyyzbNax3E",
    "outputId": "5b9f4090-51a0-4451-a89e-f65f13bab05d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19365   466   255]\n",
      " [  514  4369    58]\n",
      " [  637   150  2673]]\n",
      "Accuracy0.9269842384245446\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "RF_pred_CM2 = confusion_matrix(Y_Test, Rf2_pred)\n",
    "print(RF_pred_CM2)\n",
    "print('Accuracy' + str(accuracy_score(Y_Test, Rf2_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rYhzSSuCax3E",
    "outputId": "cc8d3234-4f77-419c-a0a0-a90a6c410e3e",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95     20086\n",
      "           1       0.88      0.88      0.88      4941\n",
      "           2       0.90      0.77      0.83      3460\n",
      "\n",
      "    accuracy                           0.93     28487\n",
      "   macro avg       0.91      0.87      0.89     28487\n",
      "weighted avg       0.93      0.93      0.93     28487\n",
      "\n",
      "\n",
      "0.9269842384245446\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_Test, Rf2_pred))\n",
    "print()\n",
    "print(accuracy_score(Y_Test, Rf2_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8aQ5bSwHjygF"
   },
   "outputs": [],
   "source": [
    "#from sklearn.linear_model.logistic import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5XOuL8v8ax3O"
   },
   "source": [
    "### Logistic regression classifier training,evaluation and confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ihKZ87jSax3O",
    "outputId": "f8bfe8b0-9fb8-483a-e707-b3ed41bf9555"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression Accuracy Score ->  90.80191076328894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    }
   ],
   "source": [
    "# fit the training dataset on the logistic rregression and predict test dataset\n",
    "Logistic = LogisticRegression()\n",
    "Logistic.fit(X_Train,Y_Train)\n",
    "Lg_pred1 = Logistic.predict(X_Test)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"Logistic regression Accuracy Score -> \",accuracy_score(Lg_pred1, Y_Test)*100)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "F3JnysVFrdXX",
    "sz2L5DARrdYR",
    "LWSgfciNrdaT"
   ],
   "name": "Journal classification_.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
